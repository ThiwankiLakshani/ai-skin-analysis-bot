INFO:__main__:Processed response from llama11b API : In the context of the image, the term "encoder" refers to a component in a neural network architecture designed for sequence-to-sequence tasks. In this architecture, one encoder processes the input and generates contextualized representations of it, while another encoder processes the input and generates contextualized representations of it. These representations serve as the basis for generating the input sequence.
INFO:__main__:Processed response from llama90b API : The image shows two encoders: one on the left and one at the top. The encoder on the left is labeled "ENCODER" and has several components, including:

*   **ADD & NORM**: This component adds and normalizes the input data.
*   **FEED FORWARD**: This component feeds forward the normalized data.
*   **MULTI-HEAD ATTENTION**: This component applies multi-head attention to the input data.
*   **MASKED MULTI-HEAD ATTENTION**: This component applies masked multi-head attention to the input data.

The encoder at the top is also labeled "ENCODER" and has similar components, including:

*   **ADD & NORM**: This component adds and normalizes the input data.
*   **FEED FORWARD**: This component feeds forward the normalized data.
*   **MULTI-HEAD ATTENTION**: This component applies multi-head attention to the input data.       
*   **MASKED MULTI-HEAD ATTENTION**: This component applies masked multi-head attention to the input data.

Both encoders have input and output embeddings, which are represented by the arrows labeled "INPUT EMBEDDINGS" and "OUTPUT EMBEDDINGS". These embeddings represent the input and output data for the encoders, respectively.
{'llama11b': 'In the context of the image, the term "encoder" refers to a component in a neural network architecture designed for sequence-to-sequence tasks. In this architecture, one encoder processes the input and generates contextualized representations of it, while another encoder processes t{'llama11b': 'In the context of the image, the term "encoder" refers to a component in a neural network architecture designed for sequence-to-sequence tasks. In this architecture, one encoder processes the input and generates contextualized representations of it, while another encoder processes twork architecture designed for sequence-to-sequence tasks. In this architecture, one encoder processes the input and generates contextualized representations of it, while another encoder processes the input and generates contextualized representations of it. These representations serve as the bashe input and generates contextualized representations of it. These representations serve as the basis for generating the input sequence.', 'llama90b': 'The image shows two encoders: one on the left and one at the top. The encoder on the left is labeled "ENCODER" and has several components, including:\n\n*   **ADD & NORM**: This component adds and normalizes the input data.\n*   **FEED FORWARD**: This component feeds forward the normalized data.\n*   **MULTI-HEAD ATTENTION**: This component applies multi-head attention to the input data.\n*   **MASKED MULTI-HEAD ATTENTION**: This componenis for generating the input sequence.', 'llama90b': 'The image shows two encoders: one on the left and one at the top. The encoder on the left is labeled "ENCODER" and has several components, including:\n\n*   **ADD & NORM**: This component adds and normalizes the input data.\n*   **FEED FORWARD**: This component feeds forward the normalized data.\n*   **MULTI-HEAD ATTENTION**: This component applies multi-head attention to the input data.\n*   **MASKED MULTI-HEAD ATTENTION**: This component applies masked multi-head attention to the input data.\n\nThe encoder at the top is also labeled "ENCODER" and has similar components, including:\n\n*   **ADD & NORM**: This component adds and normalizes the input data.\n*   **FEED FORWARD**: This component feeds forward the normalized data.\n*ing:\n\n*   **ADD & NORM**: This component adds and normalizes the input data.\n*   **FEED FORWARD**: This component feeds forward the normalized data.\n*   **MULTI-HEAD ATTENTION**: This component applies multi-head attention to the input data.\n*   **MASKED MULTI-HEAD ATTENTION**: This component applies masked multi-head attention to the input data.\n\nThe encoder at the top is also labeled "ENCODER" and has similar components, including:\n\n*   **ADD & NORM**: This component adds and normalizes the input data.\n*   **FEED FORWARD**: This component feeds forward the normalized data.\n**: This component feeds forward the normalized data.\n*   **MULTI-HEAD ATTENTION**: This component applies multi-head attention to the input data.\n*   **MASKED MULTI-HEAD ATTENTION**: This component applies masked multi-head attention to the input data.\n\nThe encoder at the top is also labeled "ENCODER" and has similar components, including:\n\n*   **ADD & NORM**: This component adds and normalizes the input data.\n*   **FEED FORWARD**: This component feeds forward the normalized data.\n*   **MULTI-HEAD ATTENTION**: This component applies multi-head attention to the input data.\n*   **t applies masked multi-head attention to the input data.\n\nThe encoder at the top is also labeled "ENCODER" and has similar components, including:\n\n*   **ADD & NORM**: This component adds and normalizes the input data.\n*   **FEED FORWARD**: This component feeds forward the normalized data.\n*   **MULTI-HEAD ATTENTION**: This component applies multi-head attention to the input data.\n*   **   **MULTI-HEAD ATTENTION**: This component applies multi-head attention to the input data.\n*   **MASKED MULTI-HEAD ATTENTION**: This component applies masked multi-head attention to the input dataMASKED MULTI-HEAD ATTENTION**: This component applies masked multi-head attention to the input data.\n\nBoth encoders have input and output embeddings, which are represented by the arrows labeled "INPUT EMBEDDINGS" and "OUTPUT EMBEDDINGS". These embeddings represent the input and output data for the encoders, respectively.'}
PS C:\Users\Thiwanki\OneDrive - NSBM\Desktop\projects\AI-DOCTOR-VOICEBOT> & "C:/Program Files/Python312/python.exe" "c:/Users/Thiwanki/OneDrive - NSBM/Desktop/projects/AI-DOCTOR-VOICEBOT/main.py"   
INFO:__main__:Processed response from llama11b API : The encoders in this image are additive and nonlinear.  One encoder in the image produces feed-forward values and the other encoder produces attention values.  Please notice that these encoders are in parallel to the decoders.  Therefore, the decoders produce additive and nonlinear values as well.
INFO:__main__:Processed response from llama90b API : There are two types of encoders in this image. Both are neural network encoders. The figure on the left is an encoder with plain attention, the figure on the left is an extended transformer model encoder.
{'llama11b': 'The encoders in this image are additive and nonlinear.  One encoder in the image produces feed-forward values and the other encoder produces attention values.  Please notice that these encoders are in parallel to the decoders.  Therefore, the decoders produce additive and nonlinear values as well.', 'llama90b': 'There are two types of encoders in this image. Both are neural network encoders. The figure on the left is an encoder with plain attention, the figure on the left is an extended transformer model encoder.'}
PS C:\Users\Thiwanki\OneDrive - NSBM\Desktop\projects\AI-DOCTOR-VOICEBOT>





n extended transformer model encoder.'}